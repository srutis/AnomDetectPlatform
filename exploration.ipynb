{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "\n",
    "# My trusty helper functions\n",
    "import time\n",
    "import random    \n",
    "\n",
    "# TODO:\n",
    "#import tensorflow\n",
    "\n",
    "def start():\n",
    "    t2 = time.perf_counter_ns()\n",
    "    options = {\n",
    "        'display': {\n",
    "            'max_columns': None,\n",
    "            'max_colwidth': 1500,\n",
    "            'max_rows': 2000000,\n",
    "            #'expand_frame_repr' : False, : 4, Wed 10 Jun 2020 11:22:29 PM EDT \n",
    "            'max_seq_items' : 100000,\n",
    "            #'precision' : 4, : Wed 10 Jun 2020 11:22:29 PM EDT \n",
    "            #'precision' : 5, : Wed 10 Jun 2020 11:22:29 PM EDT\n",
    "            'precision' : 7,\n",
    "            'width': 4500,\n",
    "            #'show_dimensions' : False, : 4, Wed 10 Jun 2020 11:22:29 PM EDT \n",
    "        },\n",
    "        'mode' : {\n",
    "            'chained_assignment' : None,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for category, option in options.items():\n",
    "        for op, value in option.items():\n",
    "            pd.set_option(f'{category}.{op}', value)\n",
    "    t3 = time.perf_counter_ns()\n",
    "    #print(f\"Panda options set in {t3 - t2} ns.\")\n",
    "    return t3 - t2\n",
    "start()\n",
    "\n",
    "def seedRNG(seed: int = 42) -> ():\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    # TODO:\n",
    "    #   import tensorflow as tf\n",
    "    #tf.random.set_seed(seed)\n",
    "    try:\n",
    "        import torch\n",
    "        torch.manual_seed(seed)\n",
    "    except:\n",
    "        None\n",
    "seedRNG()\n",
    "\n",
    "def P(*args, **kwargs):\n",
    "    print(*args, **kwargs)\n",
    "\n",
    "def t(typee):\n",
    "    return type(typee)\n",
    "    #print(type(typee), flush=True)\n",
    "    #print(\"t: \", type(typee))\n",
    "\n",
    "def xam(v):\n",
    "        tp = type(v)\n",
    "        print(f\"type(var) = {tp}.\")\n",
    "        if v is None:\n",
    "            print(f\"Skipping None singleton.\")\n",
    "            return\n",
    "        #These props do NOT exist for list!!!\n",
    "        #print(f\"var.shape = {v.shape}, var.ndim = {v.ndim}, len(var) = {len(v)}, var.size = {v.size}.\")\n",
    "        #print(f\"var.shape = {v.shape}, var.ndim = {v.ndim}, len(var) = {len(v)}\")\n",
    "        #print(f\"var.ndim = {v.ndim}, len(var) = {len(v)}\")\n",
    "        try:\n",
    "            print(f\"len(var) = {len(v)}\")\n",
    "        except:\n",
    "            None\n",
    "        if tp == np.ndarray:\n",
    "            print(f\"ndarray.dtype = {v.dtype}, ndim = {v.ndim}, shape = {v.shape}, ndarray.strides = {v.strides}, size = {v.size}, ndarray.nbytes = {v.nbytes}\")\n",
    "        elif tp == pd.Series:\n",
    "            print(f\"pd.Series: shape = {v.shape}, ndim = {v.ndim}, name = {v.name}, axes = {v.axes}, dtype = {v.dtype}, dtypes = {v.dtypes}, size = {v.size}.\")\n",
    "        elif tp == pd.DataFrame:\n",
    "            v.info()\n",
    "            print(f\"Axes of df = {v.axes}, shape= {v.shape}, ndim = {v.ndim}, columns = {v.columns}, df.dtypes = {v.dtypes}, size = {v.size}.\")\n",
    "    \n",
    "def csv(file, *args, **kwargs):\n",
    "    t0 = time.perf_counter_ns()\n",
    "    print(f\"DEBUG: csv({file}, {args}, {kwargs})\")\n",
    "\n",
    "    df = pd.read_csv(file, *args, **kwargs);\n",
    "    m0 = df.memory_usage().sum()\n",
    "    try:\n",
    "        df.drop(columns ='Unnamed: 0', inplace=True)\n",
    "    except:\n",
    "        None\n",
    "    t1 = time.perf_counter_ns()\n",
    "    print(f\"Memory used by loaded df = {m0}, time taken to load df = {t1 - t0} ns.\")\n",
    "    print(df.columns)\n",
    "    df.info()\n",
    "    m0 = df.memory_usage().sum()\n",
    "    t2 = time.perf_counter_ns()\n",
    "    print(f\"Memory used by loaded df = {m0}, time taken by csv() = {t2 - t1} ns.\")\n",
    "    del m0, t0, t1, t2,\n",
    "    return df\n",
    "\n",
    "def loaded_modules():\n",
    "    import sys\n",
    "    print(\"Modules loaded:\")\n",
    "    for i, key in enumerate(sys.modules.keys()):\n",
    "        print(f\"{i}. {key}\")\n",
    "\n",
    "#alias, synonym, symbolic link, shortcut\n",
    "mods = loaded_modules\n",
    "\n",
    "\n",
    "def ram_used():\n",
    "    #find percentage of memory used\n",
    "    memoryused= psutil.virtual_memory()\n",
    "    memoryused= float(str(memoryused).replace(\" \", \"\").split(\"percent=\")[1].split(\",\")[0])\n",
    "    msg = f\"RAM used = {memoryused}%\"\n",
    "    print(msg)\n",
    "    return msg\n",
    "\n",
    "#Note: Signature: plotly.plot(data_frame, kind, **kwargs)\n",
    "#Docstring:\n",
    "#Pandas plotting backend function, not meant to be called directly.\n",
    "#To activate, set pandas.options.plotting.backend=\"plotly\"\n",
    "#import plotly\n",
    "pd.options.plotting.backend=\"plotly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = csv('train.csv')\n",
    "print(df_train.info())\n",
    "print(df_train.head())\n",
    "print(df_train.describe())\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Equivalent: \n",
    "#df_train.plot('mean', 'sd', kind = 'scatter')import matplotlib.pyplot as plt\n",
    "# plotly.plot(df_train, kind = 'scatter', x = 'mean', y = 'sd')\n",
    "import plotly.express as px, plotly.graph_objects as go\n",
    "fig = px.scatter(df_train, x = 'mean', y = 'sd')\n",
    "fig.show()\n",
    "fig = px.histogram(df_train['mean'], nbins = 20)\n",
    "fig.show()\n",
    "fig = px.histogram(df_train['sd'], nbins = 20)\n",
    "fig.show()\n",
    "fig = px.box(df_train['mean'])\n",
    "fig.show()\n",
    "fig = px.box(df_train['sd'])\n",
    "fig.show()\n",
    "fig = px.box(df_train)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = csv('test.csv')\n",
    "print(df_test.info())\n",
    "print(df_test.head())\n",
    "print(df_test.describe())\n",
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df_test, x = 'mean', y = 'sd')\n",
    "fig.show()\n",
    "fig = px.histogram(df_test['mean'], nbins = 20)\n",
    "fig.show()\n",
    "fig = px.histogram(df_test['sd'], nbins = 20)\n",
    "fig.show()\n",
    "fig = px.box(df_test['mean'])\n",
    "fig.show()\n",
    "fig = px.box(df_test['sd'])\n",
    "fig.show()\n",
    "fig = px.box(df_test)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotly.plot(df_train, 'barh'), nbins = 20)\n",
    "# df_train['mean'].plot(kind = 'hist', bins = 20 )\n",
    "\n",
    "# df_train['sd'].plot(kind = 'hist', bins = 20 )\n",
    "\n",
    "# df_test.plot(kind = 'hist', bins = 20 )\n",
    "\n",
    "# pb1= plotly.plot(df_train, kind = 'box')\n",
    "# df_train['mean'].plot(kind = 'box')\n",
    "# print(\"pb1 == pb2:\", pb1 == pb2, \"pb1 is pb2:\", pb1 is pb2)\n",
    "# pb2.show()\n",
    "\n",
    "#df_train['sd'].plot(kind = 'box')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
